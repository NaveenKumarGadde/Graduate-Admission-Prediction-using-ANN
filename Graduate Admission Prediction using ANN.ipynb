{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the Necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv('Admission_Predict.csv')\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.2 KB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.drop('Serial No.',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data.iloc[:,:-1]\n",
    "y= Data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0        337          118                  4  4.5   4.5  9.65         1\n",
       "1        324          107                  4  4.0   4.5  8.87         1\n",
       "2        316          104                  3  3.0   3.5  8.00         1\n",
       "3        322          110                  3  3.5   2.5  8.67         1\n",
       "4        314          103                  2  2.0   3.0  8.21         0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.92\n",
       "1    0.76\n",
       "2    0.72\n",
       "3    0.80\n",
       "4    0.65\n",
       "Name: Chance of Admit , dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data set into Traing and Testimng data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>324</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>299</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>316</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>300</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>309</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>305</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "125        300          100                  3  2.0   3.0  8.66         1\n",
       "328        324          112                  4  4.0   3.5  8.77         1\n",
       "339        324          107                  5  3.5   4.0  8.66         1\n",
       "172        322          110                  4  4.0   5.0  9.13         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "347        299           94                  1  1.0   1.0  7.34         0\n",
       "41         316          105                  2  2.5   2.5  8.20         1\n",
       "180        300          104                  3  3.5   3.0  8.16         0\n",
       "132        309          105                  5  3.5   3.5  8.56         0\n",
       "224        305          105                  2  3.0   2.0  8.23         0\n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "MMS = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MMS.fit_transform(X_train)\n",
    "X_test = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22      , 0.17857143, 0.25      , ..., 0.42857143, 0.25      ,\n",
       "        1.        ],\n",
       "       [0.88      , 0.96428571, 1.        , ..., 0.85714286, 0.91911765,\n",
       "        1.        ],\n",
       "       [0.3       , 0.71428571, 0.5       , ..., 0.57142857, 0.53308824,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.70220588,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.74632353,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.22058824,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(7,activation='relu' ,input_dim =7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1, activation='linear')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 43ms/step - loss: 0.3002 - val_loss: 0.2827\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2391 - val_loss: 0.2198\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1816 - val_loss: 0.1618\n",
      "Epoch 4/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.1651"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1303 - val_loss: 0.1105\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0879 - val_loss: 0.0688\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0553 - val_loss: 0.0414\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.0265\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.0207\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - val_loss: 0.0195\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0194\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0194 - val_loss: 0.0188\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 0.0179\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0180 - val_loss: 0.0171\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.0164\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0158\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0153\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0148\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.0143\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - val_loss: 0.0134\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0088\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0046\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(X_train,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7621012669685567"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e3574d10d0>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
